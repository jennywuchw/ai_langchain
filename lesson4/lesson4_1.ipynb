{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0540c9fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "所有答案\n",
      "content='81除以9等于9。\\n\\n81 / 9 = 9\\n' additional_kwargs={} response_metadata={'model': 'gemma3:1b', 'created_at': '2025-09-27T00:46:05.7123075Z', 'done': True, 'done_reason': 'stop', 'total_duration': 585591600, 'load_duration': 189916300, 'prompt_eval_count': 18, 'prompt_eval_duration': 37888500, 'eval_count': 19, 'eval_duration': 357786800, 'model_name': 'gemma3:1b'} id='run--0cd648d3-ce94-4f4b-9b55-7ebe135ab7f9-0' usage_metadata={'input_tokens': 18, 'output_tokens': 19, 'total_tokens': 37}\n",
      "回答內容是\n",
      "81除以9等于9。\n",
      "\n",
      "81 / 9 = 9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "\n",
    "# Create a ChatOllama model\n",
    "# 透過網址的方式連結ollama (指定 base_url 指向 Ollama server)\n",
    "# 預設 Ollama server 在本機的 11434 埠，若在其他主機或埠請改成相對應的網址\n",
    "\n",
    "#model = ChatOllama(model=\"llama3.2:latest\", base_url=\"http://host.docker.internal:11434\")\n",
    "model = ChatOllama(model=\"gemma3:1b\",base_url=\"http://localhost:11434\")\n",
    "\n",
    "\n",
    "# Invoke the model with a message\n",
    "result = model.invoke(\"81除以9的答案是?\")\n",
    "print(type(result))\n",
    "print(\"所有答案\")\n",
    "print(result)\n",
    "print(\"回答內容是\")\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a094b603",
   "metadata": {},
   "source": [
    "### google-gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52de66ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: <class 'langchain_core.messages.ai.AIMessage'>\n",
      "所有答案\n",
      "content='9 * 9 = 81' additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': []} id='run--21744cf6-ae0a-40f6-8d35-5146318827a2-0' usage_metadata={'input_tokens': 5, 'output_tokens': 32, 'total_tokens': 37, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 24}}\n",
      "\n",
      "回答內容是\n",
      "9 * 9 = 81\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv  # pyright: ignore[reportMissingImports]\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI  # pyright: ignore[reportMissingImports]\n",
    "\n",
    "# Load environment variables from .env\n",
    "load_dotenv()\n",
    "\n",
    "# Create a ChatGoogleGenerativeAI model\n",
    "model = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\")\n",
    "\n",
    "#Invoke the model with a message\n",
    "result = model.invoke(\"9*9是多少\")\n",
    "print(\"Type:\", type(result))\n",
    "\n",
    "print(\"所有答案\")\n",
    "print(result)\n",
    "print()  # 加一行空白行\n",
    "\n",
    "\n",
    "print(\"回答內容是\")\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1fd6105",
   "metadata": {},
   "source": [
    "### Google Gemini\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d767906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_google_genai.chat_models.ChatGoogleGenerativeAI'>\n",
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "所有答案\n",
      "回答內容是\n",
      "金風起葉黃，\n",
      "雁南飛過江。\n",
      "楓林染層紅，\n",
      "秋意滿山崗。\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "# Load environment variables from .env\n",
    "load_dotenv()\n",
    "\n",
    "# Create a ChatGoogleGenerativeAI model\n",
    "model = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\",temperature=1)\n",
    "print(type(model))\n",
    "\n",
    "#Invoke the model with a message\n",
    "result = model.invoke(\"請用中文寫一首關於秋天的五言絕句詩\")\n",
    "print(type(result))\n",
    "print(\"所有答案\")\n",
    "#json_data = result.to_json()\n",
    "#print(json_data[\"kwargs\"][\"content\"])\n",
    "print(\"回答內容是\")\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e48a8ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "回答內容是\n"
     ]
    }
   ],
   "source": [
    "print(\"回答內容是\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
