{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53d6828d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 基本 Prompt Template 範例 ===\n",
      "\n",
      "你是一位專業的繁體中文翻譯家，具有豐富的語言學背景。\n",
      "請將使用者提供的以下英文句子翻譯成流暢、自然的繁體中文。\n",
      "\n",
      "英文句子：Do you want to go to walk with me?\n",
      "繁體中文翻譯：\n",
      "\n",
      "\n",
      "==================================================\n",
      "Ollama gemma3:1b模型回應\n",
      "以下是一些翻譯選項，各有側重，你可以根據語氣和情境選擇最適合的：\n",
      "\n",
      "**選項一 (比較正式、溫和):**\n",
      "\n",
      "*   **你想和我一起散步嗎？**\n",
      "\n",
      "**選項二 (比較口語化、親切):**\n",
      "\n",
      "*   **想和我一起走走嗎？**\n",
      "\n",
      "**選項三 (更強調「一起」):**\n",
      "\n",
      "*   **想和我一起去走走嗎？**\n",
      "\n",
      "**選項四 (略帶帶點問候):**\n",
      "\n",
      "*   **想和我一起出去走走嗎？**\n",
      "\n",
      "我建議使用 **你想和我一起散步嗎？**  這是最自然的翻譯，也符合繁體中文的語氣。\n",
      "\n",
      "希望以上翻譯對您有幫助！\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. 基本 Prompt Template 使用\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_ollama import OllamaLLM\n",
    "\n",
    "model = OllamaLLM(model=\"gemma3:1b\")\n",
    "\n",
    "# 建立翻譯模板\n",
    "template_text = \"\"\"\n",
    "你是一位專業的繁體中文翻譯家，具有豐富的語言學背景。\n",
    "請將使用者提供的以下英文句子翻譯成流暢、自然的繁體中文。\n",
    "\n",
    "英文句子：{english_sentence}\n",
    "繁體中文翻譯：\n",
    "\"\"\"\n",
    "\n",
    "# 建立 Prompt Template 實體\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"english_sentence\"],\n",
    "    template=template_text\n",
    ")\n",
    "\n",
    "# 使用模板\n",
    "formatted_prompt = prompt_template.format(english_sentence=\"Do you want to go to walk with me?\")\n",
    "print(\"=== 基本 Prompt Template 範例 ===\")\n",
    "print(formatted_prompt)\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"Ollama gemma3:1b模型回應\")\n",
    "\n",
    "response = model.invoke(formatted_prompt)\n",
    "print(response)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d26b86db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 多變數複雜模板範例 ===\n",
      "Human: \n",
      "你是一位專業的繁體中文翻譯家，專精於商業領域。\n",
      "請將以下英文文本翻譯成繁體中文，並確保：\n",
      "1. 保持原文的語氣和風格\n",
      "2. 使用專業術語\n",
      "3. 符合繁體中文的語言習慣\n",
      "\n",
      "英文文本：The quarterly revenue increased by 15% compared to last year.\n",
      "繁體中文翻譯：\n",
      "\n",
      "\n",
      "==================================================\n",
      "Ollama gemma3:1b模型回應\n",
      "以下是翻譯結果：\n",
      "\n",
      "**我們在去年Quarter的營收增長幅度為15%，超出預期。**\n",
      "\n",
      "**更正式的翻譯，更著重專業性：**\n",
      "\n",
      "**昨Quarter的營收總額較去年同期增幅為15%，表現出較高的成長潛力。**\n",
      "\n",
      "**說明：**\n",
      "\n",
      "*   **營收 (jǐngcāo)**： 這是商業用語，指總收入。\n",
      "*   **增長幅度 (zēngzhǎng kuàngdù)**： 比較準確地描述了百分比的變化。\n",
      "*   **超出預期 (kōu shōu yùqī)**： 避免過於直接的表達，更強調了數據的超出期望值。\n",
      "*   **表現出較高的成長潛力 (biǎoxiàn chū lái liángguǒ jīlì)**： 增加了一點更深層次的層次。\n",
      "\n",
      "希望這個翻譯符合您的要求！\n"
     ]
    }
   ],
   "source": [
    "# 2. 多變數的複雜模板\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_ollama import OllamaLLM\n",
    "\n",
    "model = OllamaLLM(model=\"gemma3:1b\")\n",
    "\n",
    "# 建立多變數的翻譯模板\n",
    "complex_template = \"\"\"\n",
    "你是一位專業的{target_language}翻譯家，專精於{domain}領域。\n",
    "請將以下{source_language}文本翻譯成{target_language}，並確保：\n",
    "1. 保持原文的語氣和風格\n",
    "2. 使用專業術語\n",
    "3. 符合{target_language}的語言習慣\n",
    "\n",
    "{source_language}文本：{text}\n",
    "{target_language}翻譯：\n",
    "\"\"\"\n",
    "\n",
    "# 建立 ChatPromptTemplate\n",
    "chat_prompt_template = ChatPromptTemplate.from_template(complex_template)\n",
    "\n",
    "# 使用多個變數\n",
    "formatted_prompt = chat_prompt_template.format(\n",
    "    source_language=\"英文\",\n",
    "    target_language=\"繁體中文\", \n",
    "    domain=\"商業\",\n",
    "    text=\"The quarterly revenue increased by 15% compared to last year.\"\n",
    ")\n",
    "\n",
    "print(\"=== 多變數複雜模板範例 ===\")\n",
    "print(formatted_prompt)\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"Ollama gemma3:1b模型回應\")\n",
    "\n",
    "response = model.invoke(formatted_prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b302f42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
